---
# RedHat related OSs
- name: Yum install {{ item }}
  yum:
    name: "{{ item }}"
    state: present
  with_items:
  - wget
  - tar
  - gzip
  - java-1.8.0-openjdk
  when: "ansible_os_family == 'RedHat'"

- name: Ubuntu install software-properties-common
  apt:
    name: software-properties-common
  when: ansible_distribution == "Ubuntu"

- name: Ubuntu 14 install OpenJDK PPA repo
  apt_repository:
    repo: 'ppa:openjdk-r/ppa'
  when: ansible_distribution == "Ubuntu"

# Debian related OSs
- name: "Apt install requirements"
  apt:
    name: "{{ item }}"
    state: present
    update_cache: yes
  with_items:
  - wget
  - tar
  - gzip
  - openjdk-8-jre-headless
  - openjdk-8-jdk-headless  # for jps
  when: "ansible_os_family == 'Debian'"

- name: Check that the hadoop home not exists
  stat:
    path: "{{ hadoop_home }}"
  register: hadoop_home_stat_result

- name: Get hadoop tar.gz
  get_url:
    url: "{{ hadoop_mirrors | random }}/hadoop-{{ hadoop_version }}/hadoop-{{ hadoop_version }}.tar.gz"
    dest: "/tmp/hadoop-{{ hadoop_version }}.tar.gz"
  register: result
  until: result is succeeded
  retries: 5
  delay: 1
  when:
    - hadoop_home_stat_result.stat.exists == False

- name: Check that the hadoop tar.gz exists
  stat:
    path: "/tmp/hadoop-{{ hadoop_version }}.tar.gz"
  register: stat_result
  failed_when: stat_result.stat.exists == False
  when:
    - hadoop_home_stat_result.stat.exists == False

- name: Unzip hadoop tar.gz
  unarchive: 
    src: "/tmp/hadoop-{{ hadoop_version }}.tar.gz"
    dest: /opt
    creates: "/opt/hadoop-{{ hadoop_version }}"
    copy: no
  when:
    - hadoop_home_stat_result.stat.exists == False

- name: Remove hadoop tar.gz
  file:
    path: "/tmp/hadoop-{{ hadoop_version }}.tar.gz"
    state: absent
  when:
    - hadoop_home_stat_result.stat.exists == False

- name: Rename folder
  command: "mv /opt/hadoop-{{ hadoop_version }} {{ hadoop_home }}"
  when:
    - hadoop_home_stat_result.stat.exists == False

- name: Add JAVA_HOME in ENV
  lineinfile:
    dest: "/etc/environment"
    line: "JAVA_HOME={{item}}"
  with_first_found:
    - /usr/lib/jvm/java-8-openjdk-amd64
    - /usr/lib/jvm/jre-1.8.0

- name: Add HADOOP_HOME in ENV
  lineinfile:
    dest: "/etc/environment"
    line: "HADOOP_HOME={{hadoop_home}}"

- name: Add JAVA_HOME in hadoop ENV
  lineinfile: 
    dest: "{{ hadoop_home }}/etc/hadoop/hadoop-env.sh"
    regexp: "# export\ JAVA_HOME="
    line: "export JAVA_HOME={{item}}"
  with_first_found:
    - /usr/lib/jvm/java-8-openjdk-amd64
    - /usr/lib/jvm/jre-1.8.0

- name: Add HADOOP_HOME in hadoop ENV
  lineinfile: 
    dest: "{{ hadoop_home }}/etc/hadoop/hadoop-env.sh"
    regexp: "# export\ HADOOP_HOME="
    line: "export HADOOP_HOME={{hadoop_home}}"

- name: Add HDFS user root in hadoop ENV
  blockinfile: 
    dest: "{{ hadoop_home }}/etc/hadoop/hadoop-env.sh"
    mark: "{mark} HDFS USERS"
    block: |
      export HDFS_NAMENODE_USER=root
      export HDFS_DATANODE_USER=root
      export HDFS_SECONDARYNAMENODE_USER=root

- name: Add YARN user root in hadoop ENV
  blockinfile: 
    dest: "{{ hadoop_home }}/etc/hadoop/hadoop-env.sh"
    mark: "{mark} YARN USERS"
    block: |
      export YARN_RESOURCEMANAGER_USER=root
      export YARN_NODEMANAGER_USER=root
  when:
    - yarn == True

- name: Add HTTPFS ENV
  blockinfile: 
    dest: "{{ hadoop_home }}/etc/hadoop/httpfs-env.sh"
    mark: "{mark} HTTPFS VARS"
    block: |
      export HTTPFS_HTTP_PORT=13999
      export HTTPFS_ADMIN_PORT=14002
      export HTTPFS_LOG=/var/log/httpfs.log
  when:
    - httpfs == True

- name: Add JAVA bin dir to system-wide $PATH.
  lineinfile:
    dest: "{{ item }}"
    line: 'export PATH=$PATH:$JAVA_HOME/bin'
  with_items:
    - "~/.profile"
    - "~/.bashrc"
    - "/home/cloudadm/.profile"
    - "/home/cloudadm/.bashrc"

- name: Add HADOOP bin dir to system-wide $PATH.
  lineinfile:
    dest: "{{ item }}"
    line: 'export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin'
  with_items:
    - "~/.profile"
    - "~/.bashrc"
    - "/home/cloudadm/.profile"
    - "/home/cloudadm/.bashrc"

- name: Create data dir
  file:
    path: "{{ hadoop_home }}/data"
    state: directory

- name: Create data namenode dir
  file:
    path: "{{ hadoop_home }}/data/nameNode"
    state: directory

- name: Create data datanode dir
  file:
    path: "{{ hadoop_home }}/data/dataNode"
    state: directory