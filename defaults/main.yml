## Required variables
# hadoop_master

##
# Targets: 
#   - hdfs (implemented)
#   - hdfsOnYARN
#   - hdfsOnMesos
target: hdfs
# The type of the node: master / worker
hadoop_node_type: worker
# Roles: master -> [namenode, resourcemanager] and worker -> [datanode, nodemanager]
hadoop_node_role: all
# Hadoop base directory to install the software
hadoop_home: /opt/hadoop
# List of servers to download the hadoop code
hadoop_mirrors: [ 
  "http://apache.rediris.es/hadoop/common",
  "http://apache.lauf-forum.at/hadoop/common",
  "http://www-eu.apache.org/dist/hadoop/common"
]
# Hadoop version to install
hadoop_version: 3.2.0
hadoop_2: false
# A dictionary with a set of properties to set in the hdfs-site.xml
hdfs_props: {
  # 'dfs.webhdfs.enabled': true
  'dfs.replication': 1
}
# A dictionary with a set of properties to set in the yarn-site.xml
yarn_props: {
  'yarn.acl.enable': 0,
  'yarn.nodemanager.aux-services': "mapreduce_shuffle",
  'yarn.nodemanager.resource.memory-mb': 1536,
  'yarn.scheduler.maximum-allocation-mb': 1536,
  'yarn.scheduler.minimum-allocation-mb': 128,
  'yarn.nodemanager.vmem-check-enabled': false
}

mapred_props: {
  'yarn.app.mapreduce.am.resource.mb': 512,
  'mapreduce.map.memory.mb': 256,
  'mapreduce.reduce.memory.mb': 256
}

hdfs_port: 9000

core_props: {
  'hadoop.proxyuser.root.hosts': "*",
  'hadoop.proxyuser.root.groups': "*"
}

master_key: false
master_pub_key: ""
master_priv_key: ""
worker_ips: []

yarn: false
yarn_mapred_port: 54311

httpfs: false